import os
import numpy as np
import pandas as pd
import cv2 # ç”¨äº MatrixDataset ä¸­çš„ resize
from torch.utils.data import DataLoader, Dataset
import torch
import torch.nn as nn
import torch.nn.functional as F
from torchvision import models # ç”¨äº DeepLabV3 çš„ backbone
from sklearn.model_selection import train_test_split
from natsort import natsorted
from tqdm import tqdm
from datetime import datetime
import csv
import time # å¯é€‰ï¼Œä½†æœ‰æ—¶ç”¨äºè°ƒè¯•
import math # ç”¨äº math.sqrt
import matplotlib.pyplot as plt # ç”¨äºç»˜å›¾
from complextorch import CVTensor # æ‚¨è„šæœ¬ä¸­ç”¨åˆ°çš„å¤æ•°å¼ é‡åº“

# --- 1. æ–‡ä»¶è·¯å¾„è®¾ç½® (ä¸FCNå‚è€ƒè„šæœ¬é£æ ¼ä¸€è‡´) ---
data_folder = r'E:\EMTdata' # æ‚¨è„šæœ¬æä¾›çš„è·¯å¾„

# ç»Ÿä¸€ä½¿ç”¨ _path åç¼€ä½œä¸ºæ–‡ä»¶å¤¹å˜é‡å
E_folder_path_check = os.path.join(data_folder, 'E') # ç”¨äºæ£€æŸ¥Eå­æ–‡ä»¶å¤¹æ˜¯å¦å­˜åœ¨
if not os.path.exists(E_folder_path_check):
    print(f"è­¦å‘Š: è·¯å¾„ {E_folder_path_check} ä¸å­˜åœ¨ï¼Œå°†å°è¯•ç›´æ¥åœ¨ {data_folder} ä¸‹å¯»æ‰¾ Re, Im, F æ–‡ä»¶å¤¹ã€‚")
    f_folder_path = os.path.join(data_folder, 'F')
    re_folder_path = os.path.join(data_folder, 'Re')
    im_folder_path = os.path.join(data_folder, 'Im')
else:
    f_folder_path = os.path.join(E_folder_path_check, 'F')
    re_folder_path = os.path.join(E_folder_path_check, 'Re')
    im_folder_path = os.path.join(E_folder_path_check, 'Im')

label_folder_path_check = os.path.join(data_folder, 'label') # ç”¨äºæ£€æŸ¥labelå­æ–‡ä»¶å¤¹
if not os.path.exists(label_folder_path_check):
    print(f"è­¦å‘Š: è·¯å¾„ {label_folder_path_check} ä¸å­˜åœ¨ï¼Œå°†å°è¯•ç›´æ¥åœ¨ {data_folder} ä¸‹å¯»æ‰¾ label_Re, label_Im æ–‡ä»¶å¤¹ã€‚")
    label_re_folder_path = os.path.join(data_folder, 'label_Re')
    label_im_folder_path = os.path.join(data_folder, 'label_Im')
else:
    label_re_folder_path = os.path.join(label_folder_path_check, 'label_Re')
    label_im_folder_path = os.path.join(label_folder_path_check, 'label_Im')

print(f"è¾“å…¥ Re æ–‡ä»¶å¤¹: {re_folder_path}")
print(f"è¾“å…¥ Im æ–‡ä»¶å¤¹: {im_folder_path}")
print(f"è¾“å…¥ F æ–‡ä»¶å¤¹: {f_folder_path}")
print(f"æ ‡ç­¾ Re æ–‡ä»¶å¤¹: {label_re_folder_path}")
print(f"æ ‡ç­¾ Im æ–‡ä»¶å¤¹: {label_im_folder_path}")

path_tuples_for_validation = [ # é‡å‘½åä»¥é¿å…ä¸Pythonå†…ç½®pathå†²çª
    ("è¾“å…¥Re", re_folder_path), ("è¾“å…¥Im", im_folder_path), ("è¾“å…¥F", f_folder_path),
    ("æ ‡ç­¾Re", label_re_folder_path), ("æ ‡ç­¾Im", label_im_folder_path)
]
all_paths_exist = True
for name, path_to_check in path_tuples_for_validation:
    if not os.path.isdir(path_to_check):
        print(f"é”™è¯¯: æ–‡ä»¶å¤¹ '{name}' åœ¨è·¯å¾„ '{path_to_check}' æœªæ‰¾åˆ°ã€‚")
        all_paths_exist = False
if not all_paths_exist: exit("ç¨‹åºå› è·¯å¾„é”™è¯¯è€Œç»ˆæ­¢ã€‚")

re_all_filenames = natsorted([f for f in os.listdir(re_folder_path) if f.lower().endswith('.xlsx')])
im_all_filenames = natsorted([f for f in os.listdir(im_folder_path) if f.lower().endswith('.xlsx')])
f_all_filenames = natsorted([f for f in os.listdir(f_folder_path) if f.lower().endswith('.xlsx')])
label_re_all_filenames = natsorted([f for f in os.listdir(label_re_folder_path) if f.lower().endswith('.csv')])
label_im_all_filenames = natsorted([f for f in os.listdir(label_im_folder_path) if f.lower().endswith('.csv')])

min_file_count = min(len(re_all_filenames), len(im_all_filenames), len(f_all_filenames),
                     len(label_re_all_filenames), len(label_im_all_filenames))
if min_file_count == 0: raise ValueError(f"ä¸€ä¸ªæˆ–å¤šä¸ªæ•°æ®/æ ‡ç­¾æ–‡ä»¶å¤¹ä¸ºç©ºæˆ–ä¸åŒ…å«é¢„æœŸæ–‡ä»¶ã€‚")

# ä½¿ç”¨æˆªæ–­åçš„æ–‡ä»¶åˆ—è¡¨ (ä»…æ–‡ä»¶å)
re_filenames = re_all_filenames[:min_file_count]
im_filenames = im_all_filenames[:min_file_count]
f_filenames = f_all_filenames[:min_file_count]
label_re_filenames = label_re_all_filenames[:min_file_count]
label_im_filenames = label_im_all_filenames[:min_file_count]

(re_train_files, re_val_files,
 im_train_files, im_val_files,
 f_train_files, f_val_files,
 label_re_train_files, label_re_val_files,
 label_im_train_files, label_im_val_files) = train_test_split(
    re_filenames, im_filenames, f_filenames,
    label_re_filenames, label_im_filenames,
    test_size=0.2, random_state=42
)

# --- 2. æ•°æ®é›†å®šä¹‰ (é‡‡çº³FCNå‚è€ƒè„šæœ¬ä¸­çš„ MatrixDataset) ---
def normalize_f_data(data, min_val=2.0, max_val=8.0): # ä¸FCNå‚è€ƒä¸€è‡´
    data = data.astype(np.float32)
    if (max_val - min_val) == 0: return data - min_val # é˜²æ­¢é™¤ä»¥é›¶
    return (data - min_val) / (max_val - min_val)

class MatrixDataset(Dataset): # ä»FCNå‚è€ƒè„šæœ¬å¤åˆ¶å¹¶é€‚é…
    def __init__(self, re_fnames, im_fnames, f_fnames, label_re_fnames, label_im_fnames,
                 re_mean=None, re_std=None, im_mean=None, im_std=None, calculate_stats_mode=False):
        # ä½¿ç”¨å…¨å±€å®šä¹‰çš„ folder_path å˜é‡æ¥æ„å»ºå®Œæ•´è·¯å¾„
        self.re_paths = [os.path.join(re_folder_path, f) for f in re_fnames]
        self.im_paths = [os.path.join(im_folder_path, f) for f in im_fnames]
        self.f_paths = [os.path.join(f_folder_path, f) for f in f_fnames] # ä½¿ç”¨ f_folder_path
        
        # å³ä½¿åœ¨ç»Ÿè®¡æ¨¡å¼ä¸‹ï¼Œä¹Ÿå°è¯•æ„å»ºæ ‡ç­¾è·¯å¾„åˆ—è¡¨ï¼Œå¦‚æœæ–‡ä»¶ååˆ—è¡¨ä¸ºç©ºåˆ™è·¯å¾„åˆ—è¡¨ä¹Ÿä¸ºç©º
        self.label_re_paths = [os.path.join(label_re_folder_path, f) for f in label_re_fnames] if label_re_fnames else []
        self.label_im_paths = [os.path.join(label_im_folder_path, f) for f in label_im_fnames] if label_im_fnames else []
        
        self.target_size = (512, 512) # ç›®æ ‡å°ºå¯¸

        self.re_mean, self.re_std = re_mean, re_std
        self.im_mean, self.im_std = im_mean, im_std
        self.calculate_stats_mode = calculate_stats_mode

    def __len__(self):
        return len(self.re_paths) # åŸºäºè¾“å…¥æ–‡ä»¶ç¡®å®šé•¿åº¦

    def __getitem__(self, idx):
        try:
            re_data = pd.read_excel(self.re_paths[idx], header=0, engine='openpyxl').values.astype(np.float32)
            im_data = pd.read_excel(self.im_paths[idx], header=0, engine='openpyxl').values.astype(np.float32)
            f_data_orig = pd.read_excel(self.f_paths[idx], header=0, engine='openpyxl').values.astype(np.float32)
        except Exception as e:
            print(f"è¯»å–è¾“å…¥æ–‡ä»¶æ—¶å‡ºé”™ (index {idx}): {e}, paths: R={self.re_paths[idx]}, I={self.im_paths[idx]}, F={self.f_paths[idx]}")
            raise
            
        f_data_normalized = normalize_f_data(f_data_orig) # Fé€šé“ä½¿ç”¨ç‰¹å®šå½’ä¸€åŒ–

        # ä½¿ç”¨ OpenCVè¿›è¡Œå°ºå¯¸è°ƒæ•´
        re_data_resized = cv2.resize(re_data, self.target_size, interpolation=cv2.INTER_LINEAR)
        im_data_resized = cv2.resize(im_data, self.target_size, interpolation=cv2.INTER_LINEAR)
        f_data_resized = cv2.resize(f_data_normalized, self.target_size, interpolation=cv2.INTER_LINEAR)

        if not self.calculate_stats_mode: # æ­£å¸¸è®­ç»ƒæˆ–éªŒè¯æ¨¡å¼
            if self.re_mean is not None and self.re_std is not None and self.re_std > 1e-7: # é¿å…é™¤ä»¥è¿‡å°çš„std
                re_data_resized = (re_data_resized - self.re_mean) / self.re_std
            if self.im_mean is not None and self.im_std is not None and self.im_std > 1e-7: # é¿å…é™¤ä»¥è¿‡å°çš„std
                im_data_resized = (im_data_resized - self.im_mean) / self.im_std
        
        # å †å æˆ (C, H, W) æ ¼å¼
        input_data_np = np.stack([re_data_resized, im_data_resized, f_data_resized], axis=0)
        input_tensor = torch.from_numpy(input_data_np).float()

        if self.calculate_stats_mode:
            return {'image': input_tensor} # ç»Ÿè®¡æ¨¡å¼ä¸‹ä¸è¿”å›æ ‡ç­¾

        # ç¡®ä¿åœ¨éç»Ÿè®¡æ¨¡å¼ä¸‹æ ‡ç­¾è·¯å¾„åˆ—è¡¨éç©º
        if not self.label_re_paths or not self.label_im_paths:
            raise ValueError("åœ¨éç»Ÿè®¡æ¨¡å¼ä¸‹ï¼Œæ ‡ç­¾è·¯å¾„æœªè¢«æ­£ç¡®åˆå§‹åŒ–æˆ–æ ‡ç­¾æ–‡ä»¶åˆ—è¡¨ä¸ºç©ºã€‚")

        try:
            label_re_orig = pd.read_csv(self.label_re_paths[idx], header=None).values.astype(np.float32)
            label_im_orig = pd.read_csv(self.label_im_paths[idx], header=None).values.astype(np.float32)
        except Exception as e:
            print(f"è¯»å–æ ‡ç­¾æ–‡ä»¶æ—¶å‡ºé”™ (index {idx}): {e}, paths: LR={self.label_re_paths[idx]}, LI={self.label_im_paths[idx]}")
            raise
            
        label_re_resized = cv2.resize(label_re_orig, self.target_size, interpolation=cv2.INTER_LINEAR)
        label_im_resized = cv2.resize(label_im_orig, self.target_size, interpolation=cv2.INTER_LINEAR)
        label_data_np = np.stack([label_re_resized, label_im_resized], axis=0)
        label_tensor = torch.from_numpy(label_data_np).float()

        return {'image': input_tensor, 'label': label_tensor}

# --- 3. æ¨¡å‹å®šä¹‰ (ä¿æŒæ‚¨æä¾›çš„ ComplexNet å’Œ ResnetWithComplexNet ç»“æ„) ---
class ComplexConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0): # é»˜è®¤æ­¥é•¿ä¸º1
        super(ComplexConv2d, self).__init__()
        self.real_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.imag_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)

    def forward(self, x: CVTensor) -> CVTensor: # ç±»å‹æç¤ºä»¥å¢åŠ ä»£ç æ¸…æ™°åº¦
        real_out = self.real_conv(x.real) - self.imag_conv(x.imag)
        imag_out = self.real_conv(x.imag) + self.imag_conv(x.real)
        return CVTensor(real_out, imag_out)

class ComplexReLU(nn.Module):
    def forward(self, x: CVTensor) -> CVTensor:
        return CVTensor(F.relu(x.real), F.relu(x.imag)) # ä½¿ç”¨torch.nn.functional.relu

class ComplexNet(nn.Module):
    def __init__(self):
        super(ComplexNet, self).__init__()
        # æ ¹æ®æ‚¨åŸè„šæœ¬çš„å·ç§¯æ ¸å’Œæ­¥é•¿ï¼Œè¿™ä¼šæ˜¾è‘—ç¼©å°ç©ºé—´ç»´åº¦
        # 512x512 è¾“å…¥:
        # conv1 (k3,s1,p1): 512x512
        # conv2 (k2,s2): (512-2)/2 + 1 = 256x256
        # conv3 (k2,s2): (256-2)/2 + 1 = 128x128
        # conv4 (k2,s2): (128-2)/2 + 1 = 64x64
        # è¾“å‡ºç‰¹å¾å›¾ä¸º (B, 1024å¤æ•°é€šé“, 64, 64)
        self.conv1 = ComplexConv2d(1, 128, kernel_size=3, stride=1, padding=1)
        self.relu1 = ComplexReLU()
        self.conv2 = ComplexConv2d(128, 256, kernel_size=2, stride=2) # 512->256
        self.relu2 = ComplexReLU()
        self.conv3 = ComplexConv2d(256, 512, kernel_size=2, stride=2) # 256->128
        self.relu3 = ComplexReLU()
        self.conv4 = ComplexConv2d(512, 1024, kernel_size=2, stride=2) # 128->64
        self.relu4 = ComplexReLU()

    def forward(self, x: CVTensor) -> CVTensor: # æœŸæœ›è¾“å…¥ x æ˜¯ (B, 1, H, W) çš„å¤æ•°å¼ é‡
        x = self.relu1(self.conv1(x))
        x = self.relu2(self.conv2(x))
        x = self.relu3(self.conv3(x))
        x = self.relu4(self.conv4(x)) # è¾“å‡º (B, 1024, 64, 64) å¤æ•°å¼ é‡
        return x

class ResnetWithComplexNet(nn.Module):
    def __init__(self, output_channels=2):
        super(ResnetWithComplexNet, self).__init__()
        # åŠ è½½é¢„è®­ç»ƒçš„DeepLabV3éª¨å¹²ç½‘ç»œ
        self.encoder_backbone = models.segmentation.deeplabv3_resnet50(weights=models.segmentation.DeepLabV3_ResNet50_Weights.DEFAULT).backbone
        # ResNet50 backbone çš„ 'out' (layer4) è¾“å‡º2048é€šé“ï¼Œå¯¹äº512x512è¾“å…¥ï¼Œç©ºé—´å°ºå¯¸ä¸º H/32=16x16 æˆ– H/16=32x32 (å–å†³äºå®ç°)
        # torchvisionçš„deeplabv3_resnet50æ ‡å‡†è¾“å‡ºæ­¥å¹…ä¸º16ï¼Œæ‰€ä»¥layer4è¾“å‡ºæ˜¯ (B, 2048, 32, 32)
        
        self.complex_net = ComplexNet() # ComplexNetè¾“å‡º (B, 1024å¤æ•°, 64, 64)

        # ç‰¹å¾èåˆä¸è§£ç å™¨
        # x1 æ¥è‡ªDeepLabV3 backbone: (B, 2048, 32, 32)
        # x2 æ¥è‡ªComplexNet: (B, 1024å¤æ•°, 64, 64) -> æ‹¼æ¥å®éƒ¨è™šéƒ¨å (B, 2048å®æ•°, 64, 64)
        # éœ€è¦å°† x1 ä¸Šé‡‡æ ·åˆ° 64x64 ä»¥åŒ¹é… x2 çš„ç©ºé—´ç»´åº¦
        self.decoder_in_channels = 2048 # å‡è®¾ x1 (ä¸Šé‡‡æ ·å) å’Œ x2 (å®éƒ¨è™šéƒ¨æ‹¼æ¥) éƒ½æ˜¯2048é€šé“ï¼Œç„¶åç›¸åŠ 

        self.decoder = nn.Sequential(
            # è¾“å…¥: 2048é€šé“, 64x64
            nn.Conv2d(self.decoder_in_channels, 512, kernel_size=3, padding=1, bias=False),
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(512, 256, kernel_size=4, stride=2, padding=1, bias=False), # 64x64 -> 128x128
            nn.BatchNorm2d(256),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(256, 128, kernel_size=4, stride=2, padding=1, bias=False), # 128x128 -> 256x256
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),
            nn.ConvTranspose2d(128, 64, kernel_size=4, stride=2, padding=1, bias=False), # 256x256 -> 512x512
            nn.BatchNorm2d(64),
            nn.ReLU(inplace=True),
            nn.Conv2d(64, output_channels, kernel_size=1) # æœ€ç»ˆè¾“å‡º2é€šé“
        )

    def forward(self, x_input_real_3chan: torch.Tensor) -> torch.Tensor: # è¾“å…¥æ˜¯ (B, 3, H, W) çš„å®æ•°å¼ é‡
        # è·¯å¾„1: DeepLabV3 Encoder Backbone
        # x_input_real_3chan (Re, Im, F) ç›´æ¥é€å…¥DeepLabV3çš„backbone
        x1_features = self.encoder_backbone(x_input_real_3chan)['out'] # (B, 2048, H_in/16, W_in/16), e.g., 32x32 for 512 input
        x1_upsampled = F.interpolate(x1_features, size=(64, 64), mode='bilinear', align_corners=False) # ä¸Šé‡‡æ ·åˆ°64x64

        # è·¯å¾„2: ComplexNet
        x_real_ch = x_input_real_3chan[:, 0, :, :].unsqueeze(1) # (B, 1, H, W)
        x_imag_ch = x_input_real_3chan[:, 1, :, :].unsqueeze(1) # (B, 1, H, W)
        x_complex_input = CVTensor(x_real_ch, x_imag_ch) # (B, 1, 512, 512) å¤æ•°å¼ é‡
        
        x2_complex_out = self.complex_net(x_complex_input) # è¾“å‡º: (B, 1024å¤æ•°, 64, 64)
        x2_real_concatenated = torch.cat((x2_complex_out.real, x2_complex_out.imag), dim=1) # (B, 2048å®æ•°, 64, 64)

        # ç‰¹å¾èåˆ (é€å…ƒç´ ç›¸åŠ )
        # ç¡®ä¿ x1_upsampled å’Œ x2_real_concatenated éƒ½æœ‰2048ä¸ªé€šé“
        # å½“å‰ x1_upsampled (2048é€šé“), x2_real_concatenated (2048é€šé“)
        fused_features = x1_upsampled + x2_real_concatenated 

        decoded_output = self.decoder(fused_features)
        return decoded_output

# --- 4. è®­ç»ƒé€»è¾‘ (é‡‡çº³æ ‡å‡†åŒ–æ¡†æ¶) ---
def calculate_regression_metrics(outputs, labels):
    if outputs.shape[-2:] != labels.shape[-2:]:
        outputs = F.interpolate(outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)
    mse = F.mse_loss(outputs, labels).item()
    rmse = math.sqrt(mse)
    return mse, rmse

if __name__ == '__main__':
    model_name = "ComplexNetDeepLab_Reg" # æ¨¡å‹åç§°
    checkpoint_dir = f"./{model_name}_Output" # è¾“å‡ºç›®å½•
    os.makedirs(checkpoint_dir, exist_ok=True)
    latest_model_path = os.path.join(checkpoint_dir, f"{model_name}_latest_model.pth")
    best_model_path = os.path.join(checkpoint_dir, f"{model_name}_best_model.pth")
    log_path = os.path.join(checkpoint_dir, f"{model_name}_training_log.csv")

    # --- é¢„è®¡ç®—è®­ç»ƒé›†çš„å‡å€¼å’Œæ ‡å‡†å·® ---
    print("âœ¨ æ­£åœ¨è®¡ç®—è®­ç»ƒé›†Reå’ŒImé€šé“çš„å‡å€¼å’Œæ ‡å‡†å·®...")
    stat_dataset = MatrixDataset( # ä½¿ç”¨ MatrixDataset
        re_fnames=re_train_files, im_fnames=im_train_files, f_fnames=f_train_files,
        label_re_fnames=label_re_train_files, label_im_fnames=label_im_train_files, # ç»Ÿè®¡æ—¶ä¹Ÿä¼ é€’æ–‡ä»¶ååˆ—è¡¨
        calculate_stats_mode=True
    )
    stat_loader = DataLoader(stat_dataset, batch_size=8, shuffle=False, num_workers=0) # ç»Ÿè®¡æ—¶å¯å¢å¤§batch_size

    re_sum, im_sum, re_sum_sq, im_sum_sq = 0.0, 0.0, 0.0, 0.0
    total_pixels_re, total_pixels_im = 0, 0
    for batch_data in tqdm(stat_loader, desc="è®¡ç®—ç»Ÿè®¡é‡"):
        re_ch, im_ch = batch_data['image'][:, 0, :, :], batch_data['image'][:, 1, :, :]
        re_sum += torch.sum(re_ch).item(); im_sum += torch.sum(im_ch).item()
        re_sum_sq += torch.sum(torch.square(re_ch)).item(); im_sum_sq += torch.sum(torch.square(im_ch)).item()
        total_pixels_re += re_ch.nelement(); total_pixels_im += im_ch.nelement()
    
    if not total_pixels_re or not total_pixels_im:
        print("è­¦å‘Š: ç»Ÿè®¡æ•°æ®è®¡ç®—æ—¶æœªå¤„ç†ä»»ä½•åƒç´ ã€‚Re/Imå½’ä¸€åŒ–å°†ä½¿ç”¨é»˜è®¤å€¼(mean=0, std=1)ã€‚")
        re_m_train, re_s_train, im_m_train, im_s_train = 0.0, 1.0, 0.0, 1.0
    else:
        re_m_train = re_sum / total_pixels_re; im_m_train = im_sum / total_pixels_im
        # è®¡ç®—æ–¹å·®ç„¶åå¼€æ–¹å¾—åˆ°æ ‡å‡†å·®ï¼Œmax(0,...)é˜²æ­¢æµ®ç‚¹è¯¯å·®å¯¼è‡´è´Ÿå€¼
        re_s_train = math.sqrt(max(0, (re_sum_sq/total_pixels_re) - (re_m_train**2))); re_s_train = max(re_s_train, 1e-7) # é˜²æ­¢stdä¸º0
        im_s_train = math.sqrt(max(0, (im_sum_sq/total_pixels_im) - (im_m_train**2))); im_s_train = max(im_s_train, 1e-7) # é˜²æ­¢stdä¸º0
    print(f"ç»Ÿè®¡ç»“æœ: Re(å‡å€¼={re_m_train:.4f}, æ ‡å‡†å·®={re_s_train:.4f}), Im(å‡å€¼={im_m_train:.4f}, æ ‡å‡†å·®={im_s_train:.4f})")
    print("--- ç»Ÿè®¡æ•°æ®è®¡ç®—å®Œæ¯• ---")

    # --- åˆ›å»ºæ­£å¼çš„æ•°æ®é›†å’ŒåŠ è½½å™¨ ---
    train_dataset = MatrixDataset(
        re_fnames=re_train_files, im_fnames=im_train_files, f_fnames=f_train_files,
        label_re_fnames=label_re_train_files, label_im_fnames=label_im_train_files,
        re_mean=re_m_train, re_std=re_s_train, im_mean=im_m_train, im_std=im_s_train,
        calculate_stats_mode=False # æ­£å¸¸æ¨¡å¼
    )
    # æ‚¨è„šæœ¬ä¸­ batch_size=4, num_workers=0 (ä¹‹å‰æ˜¯4ï¼Œä¸ºç»Ÿä¸€æ”¹ä¸º0)
    train_loader = DataLoader(train_dataset, batch_size=8, shuffle=True, num_workers=0, pin_memory=True, drop_last=True)

    val_loader = None
    if re_val_files: # ç¡®ä¿ä½¿ç”¨æ­£ç¡®çš„éªŒè¯é›†æ–‡ä»¶ååˆ—è¡¨
        val_dataset = MatrixDataset(
            re_fnames=re_val_files, im_fnames=im_val_files, f_fnames=f_val_files,
            label_re_fnames=label_re_val_files, label_im_fnames=label_im_val_files,
            re_mean=re_m_train, re_std=re_s_train, # éªŒè¯é›†ä¹Ÿç”¨è®­ç»ƒé›†çš„ç»Ÿè®¡æ•°æ®
            im_mean=im_m_train, im_std=im_s_train,
            calculate_stats_mode=False
        )
        val_loader = DataLoader(val_dataset, batch_size=8, shuffle=False, num_workers=0, pin_memory=True)
    else:
        print("è­¦å‘Š: æœªæ‰¾åˆ°éªŒè¯æ–‡ä»¶ï¼Œå°†è·³è¿‡éªŒè¯ã€‚æ—©åœç­–ç•¥å°†ä¸å¯ç”¨ã€‚")

    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = ResnetWithComplexNet(output_channels=2).to(device)
    
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=1e-4) # æ ‡å‡†åŒ–ä¼˜åŒ–å™¨å’Œå­¦ä¹ ç‡

    start_epoch = 0; best_val_loss = float('inf')
    train_losses_history, val_losses_history = [], []
    train_mses_history, train_rmses_history = [], []
    val_mses_history, val_rmses_history = [], []

    early_stopping_patience = 50
    early_stopping_counter = 0

    if os.path.exists(latest_model_path):
        print(f"ğŸŸ¡ æ­£åœ¨ä»æœ€æ–°çš„{model_name}æ£€æŸ¥ç‚¹æ¢å¤: {latest_model_path}")
        checkpoint = torch.load(latest_model_path, map_location=device)
        try:
            model.load_state_dict(checkpoint['model_state_dict'])
            optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
            start_epoch = checkpoint.get('epoch', -1) + 1
            best_val_loss = checkpoint.get('best_val_loss', float('inf'))
            train_losses_history=checkpoint.get('train_losses_history', [])
            val_losses_history=checkpoint.get('val_losses_history', [])
            train_mses_history=checkpoint.get('train_mses_history', [])
            train_rmses_history=checkpoint.get('train_rmses_history', [])
            val_mses_history=checkpoint.get('val_mses_history', [])
            val_rmses_history=checkpoint.get('val_rmses_history', [])
            early_stopping_counter = checkpoint.get('early_stopping_counter', 0)
            print(f"âœ… {model_name}æ¨¡å‹åŠ è½½å®Œæ¯•ã€‚å°†ä» epoch {start_epoch} å¼€å§‹ã€‚æœ€ä½³éªŒè¯Loss: {best_val_loss:.6f}, æ—©åœè®¡æ•°: {early_stopping_counter}")
        except Exception as e:
            print(f"è­¦å‘Šï¼šåŠ è½½{model_name}æ£€æŸ¥ç‚¹æ—¶å‡ºé”™ ({e})ã€‚å°†å°è¯•ä»…æ¢å¤æ¨¡å‹æƒé‡å’Œepochã€‚")
            # å°è¯•ä»…æ¢å¤æ¨¡å‹æƒé‡å’Œepochè®¡æ•°ï¼Œå…¶ä»–çŠ¶æ€é‡ç½®
            model.load_state_dict(checkpoint['model_state_dict']) # å†æ¬¡å°è¯•åŠ è½½æ¨¡å‹æƒé‡ï¼Œä»¥é˜²ä¸Šé¢éƒ¨åˆ†å¤±è´¥
            start_epoch = checkpoint.get('epoch', -1) + 1
            best_val_loss = float('inf'); early_stopping_counter = 0
            train_losses_history, val_losses_history = [], []
            train_mses_history, train_rmses_history = [], []
            val_mses_history, val_rmses_history = [], []
            print(f"éƒ¨åˆ†æ¢å¤ï¼šæ¨¡å‹æƒé‡å·²åŠ è½½ï¼Œå°†ä» epoch {start_epoch} é‡æ–°å¼€å§‹ä¼˜åŒ–å™¨å’Œå†å²è®°å½•ã€‚")
    else:
        print(f"âšª æœªæ‰¾åˆ°{model_name}æ£€æŸ¥ç‚¹ã€‚å°†ä»å¤´å¼€å§‹è®­ç»ƒã€‚")
        # åªæœ‰åœ¨ä»å¤´è®­ç»ƒä¸”æ—¥å¿—æ–‡ä»¶ä¸å­˜åœ¨æ—¶æ‰å†™å…¥è¡¨å¤´
        if not os.path.exists(log_path):
            with open(log_path, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['epoch', 'train_loss', 'train_mse', 'train_rmse', 'val_loss', 'val_mse', 'val_rmse'])
    
    print(f'è®¾å¤‡: {device}')
    num_epochs = 1000 # æ‚¨è„šæœ¬ä¸­çš„è®¾ç½®

    for epoch in range(start_epoch, num_epochs):
        model.train()
        epoch_train_loss, epoch_train_mse, epoch_train_rmse = 0.0, 0.0, 0.0
        progress_bar_train = tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs} [{model_name} è®­ç»ƒ]', ncols=120, leave=False)
        
        for batch_data in progress_bar_train:
            inputs = batch_data['image'].to(device) # (B, 3, 512, 512) å®æ•°å¼ é‡
            labels = batch_data['label'].to(device) # (B, 2, 512, 512) å®æ•°å¼ é‡
            
            optimizer.zero_grad()
            outputs = model(inputs) # æ¨¡å‹å†…éƒ¨å¤„ç†å¤æ•°é€»è¾‘ï¼Œè¾“å‡ºå®æ•°å¼ é‡
            
            if outputs.shape[-2:] != labels.shape[-2:]: # ç¡®ä¿è¾“å‡ºå’Œæ ‡ç­¾å°ºå¯¸ä¸€è‡´
                outputs = F.interpolate(outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)
            
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            mse, rmse = calculate_regression_metrics(outputs.detach(), labels.detach())
            epoch_train_loss += loss.item()
            epoch_train_mse += mse
            epoch_train_rmse += rmse
            progress_bar_train.set_postfix(loss=loss.item(), mse=mse, rmse=rmse)
        progress_bar_train.close()

        avg_epoch_train_loss = epoch_train_loss / len(train_loader) if len(train_loader) > 0 else 0
        avg_epoch_train_mse = epoch_train_mse / len(train_loader) if len(train_loader) > 0 else 0
        avg_epoch_train_rmse = epoch_train_rmse / len(train_loader) if len(train_loader) > 0 else 0
        train_losses_history.append(avg_epoch_train_loss)
        train_mses_history.append(avg_epoch_train_mse)
        train_rmses_history.append(avg_epoch_train_rmse)
        tqdm.write(f"Epoch {epoch+1} [{model_name} è®­ç»ƒæ€»ç»“]: Loss={avg_epoch_train_loss:.4f}, MSE={avg_epoch_train_mse:.4f}, RMSE={avg_epoch_train_rmse:.4f}")

        avg_epoch_val_loss, avg_epoch_val_mse, avg_epoch_val_rmse = float('nan'), float('nan'), float('nan')
        progress_bar_val = None # åˆå§‹åŒ–éªŒè¯è¿›åº¦æ¡å˜é‡

        if val_loader:
            model.eval()
            epoch_val_loss, epoch_val_mse, epoch_val_rmse = 0.0,0.0,0.0
            with torch.no_grad():
                progress_bar_val = tqdm(val_loader, desc=f'Epoch {epoch+1}/{num_epochs} [{model_name} éªŒè¯]', ncols=120, leave=False)
                for batch_data in progress_bar_val:
                    inputs = batch_data['image'].to(device)
                    labels = batch_data['label'].to(device)
                    outputs = model(inputs)
                    if outputs.shape[-2:] != labels.shape[-2:]:
                         outputs = F.interpolate(outputs, size=labels.shape[-2:], mode='bilinear', align_corners=False)
                    loss = criterion(outputs, labels)
                    mse, rmse = calculate_regression_metrics(outputs, labels) # åœ¨no_gradä¸‹ï¼Œdetachä¸æ˜¯å¿…é¡»çš„ï¼Œä½†æ— å®³
                    epoch_val_loss += loss.item(); epoch_val_mse += mse; epoch_val_rmse += rmse
                    progress_bar_val.set_postfix(loss=loss.item(), mse=mse, rmse=rmse)
            if progress_bar_val: progress_bar_val.close()

            avg_epoch_val_loss = epoch_val_loss / len(val_loader) if len(val_loader) > 0 else 0
            avg_epoch_val_mse = epoch_val_mse / len(val_loader) if len(val_loader) > 0 else 0
            avg_epoch_val_rmse = epoch_val_rmse / len(val_loader) if len(val_loader) > 0 else 0
            val_losses_history.append(avg_epoch_val_loss); val_mses_history.append(avg_epoch_val_mse); val_rmses_history.append(avg_epoch_val_rmse)
            tqdm.write(f"Epoch {epoch+1} [{model_name} éªŒè¯æ€»ç»“]: Loss={avg_epoch_val_loss:.4f}, MSE={avg_epoch_val_mse:.4f}, RMSE={avg_epoch_val_rmse:.4f}")

            if not math.isnan(avg_epoch_val_loss): # ç¡®ä¿éªŒè¯æŸå¤±æœ‰æ•ˆ
                if avg_epoch_val_loss < best_val_loss:
                    best_val_loss = avg_epoch_val_loss
                    early_stopping_counter = 0 
                    torch.save({
                        'epoch': epoch, 'model_state_dict': model.state_dict(),
                        'optimizer_state_dict': optimizer.state_dict(), 'best_val_loss': best_val_loss,
                        'train_losses_history': train_losses_history, 'val_losses_history': val_losses_history,
                        'train_mses_history': train_mses_history, 'train_rmses_history': train_rmses_history,
                        'val_mses_history': val_mses_history, 'val_rmses_history': val_rmses_history,
                        'early_stopping_counter': early_stopping_counter # ä¿å­˜é‡ç½®åçš„è®¡æ•°å™¨
                    }, best_model_path)
                    tqdm.write(f"âœ… {model_name} æœ€ä½³æ¨¡å‹å·²ä¿å­˜, éªŒè¯Loss: {best_val_loss:.6f}")
                else:
                    early_stopping_counter += 1
                    tqdm.write(f"ğŸŸ¡ {model_name} æ—©åœè®¡æ•°å™¨: {early_stopping_counter}/{early_stopping_patience} (å½“å‰éªŒè¯Loss: {avg_epoch_val_loss:.6f}, æœ€ä½³: {best_val_loss:.6f})")
        else: # å¦‚æœæ²¡æœ‰éªŒè¯åŠ è½½å™¨
            val_losses_history.append(float('nan')); val_mses_history.append(float('nan')); val_rmses_history.append(float('nan'))

        # ä¿å­˜æœ€æ–°æ¨¡å‹æ£€æŸ¥ç‚¹
        torch.save({
            'epoch': epoch, 'model_state_dict': model.state_dict(),
            'optimizer_state_dict': optimizer.state_dict(), 'best_val_loss': best_val_loss,
            'train_losses_history': train_losses_history, 'val_losses_history': val_losses_history,
            'train_mses_history': train_mses_history, 'train_rmses_history': train_rmses_history,
            'val_mses_history': val_mses_history, 'val_rmses_history': val_rmses_history,
            'early_stopping_counter': early_stopping_counter # ä¿å­˜å½“å‰çš„æ—©åœè®¡æ•°å™¨
        }, latest_model_path)

        # CSVæ—¥å¿—è®°å½•
        with open(log_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([epoch + 1, avg_epoch_train_loss, avg_epoch_train_mse, avg_epoch_train_rmse,
                             f"{avg_epoch_val_loss:.4f}" if not math.isnan(avg_epoch_val_loss) else "N/A",
                             f"{avg_epoch_val_mse:.4f}" if not math.isnan(avg_epoch_val_mse) else "N/A",
                             f"{avg_epoch_val_rmse:.4f}" if not math.isnan(avg_epoch_val_rmse) else "N/A"])
        
        # æ—©åœæ£€æŸ¥
        if val_loader and early_stopping_counter >= early_stopping_patience:
            tqdm.write(f"ğŸ”´ {model_name} æ—©åœè§¦å‘ï¼éªŒè¯æŸå¤±å·²è¿ç»­ {early_stopping_patience} ä¸ªè½®æ¬¡æ²¡æœ‰æ”¹å–„ã€‚åœ¨ Epoch {epoch + 1} åœæ­¢è®­ç»ƒã€‚")
            break # è·³å‡ºä¸»è®­ç»ƒå¾ªç¯
            
    tqdm.write(f'ğŸ {model_name} è®­ç»ƒå®Œæˆã€‚')

    # ç»˜å›¾
    plt.figure(figsize=(18, 6)) # è®¾ç½®å›¾è¡¨å¤§å°
    plt.subplot(1, 3, 1); plt.plot(train_losses_history, label='è®­ç»ƒæŸå¤±'); plt.plot(val_losses_history, label='éªŒè¯æŸå¤±', linestyle='--'); plt.xlabel('è½®æ¬¡'); plt.ylabel('æŸå¤±'); plt.legend(); plt.title(f'{model_name} æŸå¤±'); plt.grid(True)
    plt.subplot(1, 3, 2); plt.plot(train_mses_history, label='è®­ç»ƒMSE'); plt.plot(val_mses_history, label='éªŒè¯MSE', linestyle='--'); plt.xlabel('è½®æ¬¡'); plt.ylabel('MSE'); plt.legend(); plt.title(f'{model_name} MSE'); plt.grid(True)
    plt.subplot(1, 3, 3); plt.plot(train_rmses_history, label='è®­ç»ƒRMSE'); plt.plot(val_rmses_history, label='éªŒè¯RMSE', linestyle='--'); plt.xlabel('è½®æ¬¡'); plt.ylabel('RMSE'); plt.legend(); plt.title(f'{model_name} RMSE'); plt.grid(True)
    plt.tight_layout(); plt.savefig(os.path.join(checkpoint_dir, f"{model_name}_training_metrics_zh.png"))
    print(f"ğŸ“ˆ {model_name} è®­ç»ƒæŒ‡æ ‡å›¾è¡¨å·²ä¿å­˜åˆ° {os.path.join(checkpoint_dir, f'{model_name}_training_metrics_zh.png')}")