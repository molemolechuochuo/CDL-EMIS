import os
import numpy as np
import pandas as pd
import torch.nn.functional as F
from torch.utils.data import DataLoader, Dataset
import torch
import torch.nn as nn
from torchvision import models
from sklearn.model_selection import train_test_split
from natsort import natsorted
# import complextorch as cvtorch
# import complextorch.nn as cvnn
from complextorch import CVTensor
# import matplotlib.pyplot as plt
from tqdm import tqdm
import torch.nn.functional as F
from datetime import datetime
import csv

# è®¾ç½®æ–‡ä»¶è·¯å¾„
data_folder = r'E:\CellSegnetTset\U-net-master\dataset6_18_8ç”µåœº\çŸ©é˜µ'
re_folder = os.path.join(data_folder, 'Re')
im_folder = os.path.join(data_folder, 'Im')
F_folder = os.path.join(data_folder, 'F')  # æ·»åŠ é¢‘ç‡æ•°æ®æ–‡ä»¶å¤¹è·¯å¾„
label_re_folder = os.path.join(data_folder, 'label_Re')
label_im_folder = os.path.join(data_folder, 'label_Im')

re_files = natsorted(os.listdir(re_folder))
im_files = natsorted(os.listdir(im_folder))
F_files = natsorted(os.listdir(F_folder))  # è·å–é¢‘ç‡æ•°æ®æ–‡ä»¶åˆ—è¡¨
label_re_files = natsorted(os.listdir(label_re_folder))
label_im_files = natsorted(os.listdir(label_im_folder))

# æŒ‰80/20çš„æ¯”ä¾‹åˆ’åˆ†è®­ç»ƒé›†å’Œæµ‹è¯•é›†
re_train_files, re_test_files, im_train_files, im_test_files, F_train_files, F_test_files, label_re_train_files, label_re_test_files, label_im_train_files, label_im_test_files = train_test_split(
    re_files, im_files, F_files, label_re_files, label_im_files, test_size=0.2, random_state=42
)

# å®šä¹‰å½’ä¸€åŒ–å‡½æ•°
def normalize(data):
    return (data - data.min()) / (data.max() - data.min())

def normalize_f_data(data, min_val=2.0, max_val=8.0):
    return (data - min_val) / (max_val - min_val)

class CustomDataset(Dataset):
    def __init__(self, re_paths, im_paths, F_paths, label_re_paths, label_im_paths, transform=None):
        self.re_paths = re_paths
        self.im_paths = im_paths
        self.F_paths = F_paths
        self.label_re_paths = label_re_paths
        self.label_im_paths = label_im_paths
        self.transform = transform

    def __len__(self):
        return len(self.re_paths)

    def __getitem__(self, idx):
        re_path = self.re_paths[idx]
        im_path = self.im_paths[idx]
        F_path = self.F_paths[idx]
        label_re_path = self.label_re_paths[idx]
        label_im_path = self.label_im_paths[idx]

        # è¯»å–æ•°æ®
        re_data = pd.read_excel(re_path, header=0, engine='openpyxl').values
        im_data = pd.read_excel(im_path, header=0, engine='openpyxl').values
        F_data = pd.read_excel(F_path, header=0, engine='openpyxl').values  # è¯»å–é¢‘ç‡æ•°æ®
        label_re_data = pd.read_csv(label_re_path, header=None).values
        label_im_data = pd.read_csv(label_im_path, header=None).values

        # å°†æ•°æ®è½¬æ¢ä¸ºæµ®ç‚¹æ•°
        re_data = normalize(re_data.astype(np.float32))  # æ™®é€šå½’ä¸€åŒ–
        im_data = normalize(im_data.astype(np.float32))  # æ™®é€šå½’ä¸€åŒ–
        F_data = normalize_f_data(F_data.astype(np.float32))  # å½’ä¸€åŒ–é¢‘ç‡æ•°æ®
        label_re_data = label_re_data.astype(np.float32)
        label_im_data = label_im_data.astype(np.float32)

        # è°ƒæ•´å¤§å°ä¸º 512x512ï¼Œå¹¶æ·»åŠ é¢‘ç‡ç»´åº¦
        re_data = torch.nn.functional.interpolate(torch.from_numpy(np.expand_dims(re_data, axis=0)).unsqueeze(0), size=(512,512), mode='bilinear', align_corners=True).squeeze(0)
        im_data = torch.nn.functional.interpolate(torch.from_numpy(np.expand_dims(im_data, axis=0)).unsqueeze(0), size=(512,512), mode='bilinear', align_corners=True).squeeze(0)
        F_data = torch.nn.functional.interpolate(torch.from_numpy(np.expand_dims(F_data, axis=0)).unsqueeze(0), size=(512,512), mode='bilinear', align_corners=True).squeeze(0)

        label_re_data = torch.nn.functional.interpolate(torch.from_numpy(np.expand_dims(label_re_data, axis=0)).unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=True).squeeze(0)
        label_im_data = torch.nn.functional.interpolate(torch.from_numpy(np.expand_dims(label_im_data, axis=0)).unsqueeze(0), size=(512, 512), mode='bilinear', align_corners=True).squeeze(0)

        # å°†å®éƒ¨å’Œè™šéƒ¨ç»“åˆä¸ºæ™®é€šå¼ é‡ï¼Œå¹¶æ·»åŠ é¢‘ç‡æ•°æ®
        image = torch.cat((re_data, im_data, F_data), dim=0)  # å½¢çŠ¶ä¸º (3, 512, 512)
        label = torch.cat((label_re_data, label_im_data), dim=0)  # å½¢çŠ¶ä¸º (2, 512, 512) 

        return {'image': image, 'label': label}
    
def calculate_metrics(outputs, labels):
    mse = F.mse_loss(outputs, labels).item()
    rmse = torch.sqrt(F.mse_loss(outputs, labels)).item()
    return mse, rmse

# å®šä¹‰å¤æ•°å·ç§¯å±‚å’Œæ¿€æ´»å‡½æ•°
class ComplexConv2d(nn.Module):
    def __init__(self, in_channels, out_channels, kernel_size, stride=2, padding=0):
        super(ComplexConv2d, self).__init__()
        self.real_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)
        self.imag_conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)

    def forward(self, x):
        real = self.real_conv(x.real) - self.imag_conv(x.imag)
        imag = self.real_conv(x.imag) + self.imag_conv(x.real)
        return CVTensor(real, imag)

class ComplexReLU(nn.Module):
    def forward(self, x):
        real = torch.relu(x.real)
        imag = torch.relu(x.imag)
        return CVTensor(real, imag)

# å®šä¹‰å¤æ•°ç½‘ç»œ
class ComplexNet(nn.Module):
    def __init__(self):
        super(ComplexNet, self).__init__()
        self.conv1 = ComplexConv2d(1, 128, kernel_size=3 ,stride=1, padding=1)
        self.relu1 = ComplexReLU()
        self.conv2 = ComplexConv2d(128, 256, kernel_size=2)
        self.relu2 = ComplexReLU()
        self.conv3 = ComplexConv2d(256, 512, kernel_size=2)
        self.relu3 = ComplexReLU()
        self.conv4 = ComplexConv2d(512, 1024, kernel_size=2)
        self.relu4 = ComplexReLU()

    def forward(self, x):
        # torch.Size([2, 1, 512, 512])  
        x = self.relu1(self.conv1(x)) #torch.Size([2, 16, 512, 512])
        x = self.relu2(self.conv2(x)) #torch.Size([2, 16, 512, 512])
        x = self.relu3(self.conv3(x)) #torch.Size([2, 64, 512, 512])
        x = self.relu4(self.conv4(x)) #torch.Size([2, 128, 512, 512])
        return x

# å®šä¹‰ DeepLabV3 æ¨¡å‹å¹¶ç»“åˆå¤æ•°ç½‘ç»œ
class DeepLabV3WithComplexNet(nn.Module):
    def __init__(self):
        super(DeepLabV3WithComplexNet, self).__init__()

        # DeepLabV3 çš„ç¼–ç å™¨éƒ¨åˆ†
        self.encoder = models.segmentation.deeplabv3_resnet50(pretrained=True)
        self.encoder.classifier = nn.Identity()  # ç§»é™¤ DeepLabV3 çš„åˆ†ç±»å¤´

        # å¤æ•°ç½‘ç»œ
        self.complex_net = ComplexNet()

        # Decoder éƒ¨åˆ†
        self.decoder = nn.Sequential(
            nn.Conv2d(2048, 512, kernel_size=3, padding=1),  # è¾“å…¥é€šé“æ•°æ”¹ä¸º 2048 + 1024
            nn.BatchNorm2d(512),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2),
            nn.Conv2d(256, 128, kernel_size=3, padding=1),
            nn.BatchNorm2d(128),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2),
            nn.Conv2d(64, 32, kernel_size=3, padding=1),
            nn.BatchNorm2d(32),
            nn.ReLU(inplace=True),

            nn.ConvTranspose2d(32, 16, kernel_size=2, stride=2),
            nn.Conv2d(16, 2, kernel_size=1)  # æœ€åè¾“å‡º2ä¸ªé€šé“
        )

    def forward(self, x):
        # å°†è¾“å…¥æ•°æ®åˆ†ç¦»æˆå®éƒ¨ã€è™šéƒ¨å’Œé¢‘ç‡éƒ¨åˆ†
        # torch.Size([2, 3, 512, 512])
        x_real = x[:, 0, :, :]
        x_imag = x[:, 1, :, :]
        x_freq = x[:, 2, :, :]  # æ·»åŠ ä¸€ä¸ªç»´åº¦ä»¥åŒ¹é…å·ç§¯å±‚çš„è¾“å…¥å½¢çŠ¶
        x_complex = CVTensor(x_real, x_imag)

        # å°†æ‰€æœ‰é€šé“ç»„åˆå¹¶ä¼ é€’ç»™ DeepLabV3 çš„ç¼–ç å™¨éƒ¨åˆ†
        x_combined = torch.cat((x_real.unsqueeze(1), x_imag.unsqueeze(1), x_freq.unsqueeze(1)), dim=1)
        #torch.Size([2, 3, 512, 512]) é€è¿›Encoderçš„
        # ç»„åˆçš„æ•°æ®è¿›å…¥ç¼–ç å™¨
        x1 = self.encoder.backbone(x_combined)['out'] 
        # torch.Size([2, 2048, 64, 64]) #å‡ºEncoderçš„
        
        x_complex = CVTensor(x_real.squeeze(1), x_imag.squeeze(1))  # æ¢å¤ä¸º [batch_size, height, width]

        # æ‰‹åŠ¨æ·»åŠ ä¸€ä¸ªç»´åº¦ä»¥åŒ¹é…å¤æ•°ç½‘ç»œçš„è¾“å…¥è¦æ±‚
        x_complex.real = x_complex.real.unsqueeze(1)  # [batch_size, 1, height, width]
        x_complex.imag = x_complex.imag.unsqueeze(1)  # [batch_size, 1, height, width]
        # è½¬ç½®æ“ä½œï¼Œå°†å½¢çŠ¶ä» [batch_size, height, width] è½¬æ¢ä¸º [1, batch_size, height, width]
        x_complex.real = x_complex.real.permute(0, 1, 2, 3)
        x_complex.imag = x_complex.imag.permute(0, 1, 2, 3)

        # è°ƒæ•´å¤§å°ä»¥åŒ¹é…ç¼–ç å™¨è¾“å‡º
        x2 = self.complex_net(x_complex)
        # torch.Size([2, 512, 512, 512])
        x2 = torch.cat((x2.real, x2.imag), dim=1)  # [batch_size, 2 * channels, height, width]
        # torch.Size([2, 1024, 512, 512])
        # x2 = nn.functional.interpolate(x2, size=x1.shape[2:], mode='bilinear', align_corners=True)
        # torch.Size([2, 1024, 64, 64])


        x = x1+x2
        # x = torch.cat((x1, x2), dim=1)
        # torch.Size([2, 3072, 64, 64])
        x = self.decoder(x)
        return x

if __name__ == '__main__':

    # è·å–æ•°æ®é›†
    train_dataset = CustomDataset(
        re_paths=[os.path.join(re_folder, f) for f in re_train_files],
        im_paths=[os.path.join(im_folder, f) for f in im_train_files],
        F_paths=[os.path.join(F_folder, f) for f in F_train_files],  # ä¼ é€’é¢‘ç‡æ•°æ®è·¯å¾„
        label_re_paths=[os.path.join(label_re_folder, f) for f in label_re_train_files],
        label_im_paths=[os.path.join(label_im_folder, f) for f in label_im_train_files]
    )
    train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True, num_workers=4, pin_memory=True)

    test_dataset = CustomDataset(
        re_paths=[os.path.join(re_folder, f) for f in re_test_files],
        im_paths=[os.path.join(im_folder, f) for f in im_test_files],
        F_paths=[os.path.join(F_folder, f) for f in F_test_files],  # ä¼ é€’é¢‘ç‡æ•°æ®è·¯å¾„
        label_re_paths=[os.path.join(label_re_folder, f) for f in label_re_test_files],
        label_im_paths=[os.path.join(label_im_folder, f) for f in label_im_test_files]
    )
    test_loader = DataLoader(test_dataset, batch_size=4, shuffle=False, num_workers=4, pin_memory=True)

    # å®šä¹‰æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    model = DeepLabV3WithComplexNet().to(device)
    criterion = nn.MSELoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
  
    save_path = "./best_model.pth"
    best_val_loss = float('inf') 

  # è®­ç»ƒè¿‡ç¨‹
    num_epochs = 1000
    train_losses, val_losses = [], []
    train_mse, train_rmse, val_mse, val_rmse = [], [], [], []

    print('è®­ç»ƒåˆå§‹åŒ–å®Œæˆ')

    # sshçªç„¶æ–­è”äº†ï¼ï¼ï¼
    # å¦‚æœæœ‰ä¿å­˜çš„æ¨¡å‹ï¼Œå°±åŠ è½½
    resume_path = r"D:\workspace\liyuzhe\best_model.pth"
    start_epoch = 0
    best_val_loss = float('inf')

    if os.path.exists(resume_path):
        print("ğŸŸ¡ æ£€æµ‹åˆ°å·²æœ‰æ¨¡å‹ checkpointï¼Œæ­£åœ¨åŠ è½½...")
        checkpoint = torch.load(resume_path, map_location=device)
        model.load_state_dict(checkpoint['model_state_dict'])
        optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        start_epoch = checkpoint['epoch'] + 1
        best_val_loss = checkpoint['best_val_loss']
        print(f"âœ… æ¨¡å‹åŠ è½½å®Œæ¯•ï¼Œå°†ä» epoch {start_epoch} å¼€å§‹ç»§ç»­è®­ç»ƒï¼Œå½“å‰æœ€ä¼˜éªŒè¯ Lossï¼š{best_val_loss:.6f}")


    # è®¡ç®—å¹¶æ‰“å° MSE å’Œ RMSE
    for epoch in range(num_epochs):
        model.train()
        running_loss = 0.0
        running_mse = 0.0
        running_rmse = 0.0
        train_steps = 0
        print(f"æ­£åœ¨è¿›è¡Œç¬¬{epoch}epochè®­ç»ƒ")

        for step, batch in enumerate(tqdm(train_loader,desc=f'epoch{epoch}',ncols=130)):
            inputs = batch['image'].to(device)
            labels = batch['label'].to(device)

            optimizer.zero_grad()
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            loss.backward()
            optimizer.step()

            mse, rmse = calculate_metrics(outputs, labels)
            running_loss += loss.item()
            running_mse += mse
            running_rmse += rmse
            train_steps += 1

            # æ‰“å°æ¯ä¸€æ­¥çš„ä¿¡æ¯
            if (step + 1) % 10 == 0:  # æ¯10ä¸ªæ‰¹æ¬¡æ‰“å°ä¸€æ¬¡
                timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
                print(f"[{timestamp}] [Epoch {epoch+1}/{num_epochs}] Step {step+1}/{len(train_loader)} "
                    f"Loss: {loss.item():.4f}, MSE: {mse:.4f}, RMSE: {rmse:.4f}")


        train_loss = running_loss / train_steps
        train_losses.append(train_loss)
        train_mse_val = running_mse / train_steps
        train_rmse_val = running_rmse / train_steps
        train_mse.append(train_mse_val)
        train_rmse.append(train_rmse_val)

        # éªŒè¯è¿‡ç¨‹
        model.eval()
        val_loss = 0.0
        val_mse_epoch = 0.0
        val_rmse_epoch = 0.0
        val_steps = 0
        with torch.no_grad():
            for batch in test_loader:
                inputs = batch['image'].to(device)
                labels = batch['label'].to(device)
                outputs = model(inputs)
                loss = criterion(outputs, labels)
                val_loss += loss.item()

                mse, rmse = calculate_metrics(outputs, labels)
                val_mse_epoch += mse
                val_rmse_epoch += rmse
                val_steps += 1

        val_loss /= val_steps
        val_losses.append(val_loss)
        val_mse_val = val_mse_epoch / val_steps
        val_rmse_val = val_rmse_epoch / val_steps
        val_mse.append(val_mse_val)
        val_rmse.append(val_rmse_val)

            # å¦‚æœå½“å‰éªŒè¯é›†ä¸Šçš„ loss æ›´å°ï¼Œå°±ä¿å­˜æ¨¡å‹
        if val_loss < best_val_loss:
            best_val_loss = val_loss
            torch.save({
                'epoch': epoch,
                'model_state_dict': model.state_dict(),
                'optimizer_state_dict': optimizer.state_dict(),
                'best_val_loss': best_val_loss
            }, save_path)
            print(f"âœ… æ¨¡å‹å·²ä¿å­˜ï¼Œå½“å‰æœ€ä¼˜éªŒè¯ Lossï¼š{best_val_loss:.6f}")

        #ä¿å­˜æ—¥å¿—
        log_path = "training_log.csv"
        # å¦‚æœæ–‡ä»¶ä¸å­˜åœ¨ï¼Œå…ˆå†™è¡¨å¤´
        if not os.path.exists(log_path):
            with open(log_path, 'w', newline='') as f:
                writer = csv.writer(f)
                writer.writerow(['epoch', 'train_loss', 'train_mse', 'train_rmse', 'val_loss', 'val_mse', 'val_rmse'])
        # åœ¨æ¯ä¸ª epoch ç»“æŸæ—¶ä¿å­˜
        with open(log_path, 'a', newline='') as f:
            writer = csv.writer(f)
            writer.writerow([epoch, train_loss, train_mse_val, train_rmse_val, val_loss, val_mse_val, val_rmse_val])